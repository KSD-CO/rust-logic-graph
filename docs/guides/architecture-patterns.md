# ğŸ—ï¸ Architecture Patterns

> Real-world patterns for building distributed reasoning systems with Rust Logic Graph

---

## ğŸ“‹ Pattern Catalog

| Pattern | Use Case | Complexity |
|---------|----------|------------|
| [Multi-Database Reasoning](#pattern-1-multi-database-reasoning) | Aggregate data from multiple sources | â­â­ |
| [AI Agent with Tools](#pattern-2-ai-agent-with-tool-calling) | LLM orchestration with external tools | â­â­â­ |
| [Saga Pattern](#pattern-3-saga-pattern-for-distributed-transactions) | Distributed transactions with compensation | â­â­â­â­ |
| [RAG Pipeline](#pattern-4-rag-retrieval-augmented-generation) | Vector search + LLM generation | â­â­â­ |
| [Event-Driven Reasoning](#pattern-5-event-driven-reasoning) | React to events with business rules | â­â­â­ |
| [Multi-Agent Coordination](#pattern-6-multi-agent-coordination) | Coordinate multiple AI agents | â­â­â­â­ |

---

## Pattern 1: Multi-Database Reasoning

### Problem
Your data lives in multiple databases (PostgreSQL, MongoDB, Redis). You need to query all of them, aggregate the data, apply business rules, and make a decision.

### Solution
```rust
use rust_logic_graph::{Graph, NodeConfig, NodeType, Edge};

let graph = Graph::new()
    // Data collection from multiple sources
    .add_node("user_profile", NodeConfig {
        node_type: NodeType::DBNode {
            database: "postgres",
            query: "SELECT * FROM users WHERE id = $1".to_string(),
        },
        ..Default::default()
    })
    .add_node("analytics", NodeConfig {
        node_type: NodeType::DBNode {
            database: "mongodb",
            query: r#"{ "collection": "user_analytics", "filter": { "user_id": "$user_id" } }"#.to_string(),
        },
        ..Default::default()
    })
    .add_node("cache_check", NodeConfig {
        node_type: NodeType::DBNode {
            database: "redis",
            query: "GET recommendation:$user_id".to_string(),
        },
        ..Default::default()
    })
    
    // Apply business rules
    .add_node("recommendation_engine", NodeConfig {
        node_type: NodeType::RuleNode {
            rules_file: "recommendation_rules.grl".to_string(),
        },
        dependencies: vec!["user_profile", "analytics", "cache_check"],
        ..Default::default()
    })
    
    // Decision node
    .add_node("make_decision", NodeConfig {
        node_type: NodeType::ConditionalNode {
            condition: "confidence_score > 0.8".to_string(),
            true_branch: "send_recommendation".to_string(),
            false_branch: "fallback_logic".to_string(),
        },
        dependencies: vec!["recommendation_engine"],
        ..Default::default()
    });
```

### Architecture Diagram
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL â”‚    â”‚   MongoDB   â”‚    â”‚    Redis    â”‚
â”‚  (Users)    â”‚    â”‚ (Analytics) â”‚    â”‚   (Cache)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Rule Engine  â”‚â—€â”€â”€â”€ GRL Business Rules
                  â”‚  (Reasoning)  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Decision Node â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Send Recommendâ”‚         â”‚ Fallback Logic  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Benefits
- âœ… Query multiple databases in parallel
- âœ… Apply complex business logic with GRL
- âœ… Type-safe data aggregation
- âœ… Automatic error handling

---

## Pattern 2: AI Agent with Tool Calling

### Problem
Build an AI agent that can:
1. Understand user queries
2. Call external tools (search, database, APIs)
3. Reason over the results
4. Validate with business rules

### Solution
```rust
// Define tool subgraphs
let search_tool = GraphDef::from_yaml("tools/search.yaml")?;
let database_tool = GraphDef::from_yaml("tools/database.yaml")?;
let calculator_tool = GraphDef::from_yaml("tools/calculator.yaml")?;

let agent_graph = Graph::new()
    // Step 1: Understand the query
    .add_node("understand", NodeConfig {
        node_type: NodeType::AINode {
            provider: "claude",
            model: "claude-3-5-sonnet-20241022".to_string(),
            system_prompt: "You are a helpful assistant. Analyze the query and decide which tools to call.".to_string(),
        },
        ..Default::default()
    })
    
    // Step 2: Call tools in parallel
    .add_node("search_knowledge", NodeConfig {
        node_type: NodeType::SubgraphNode {
            graph_def: search_tool,
            input_mapping: vec![("query", "search_query")],
            output_key: "search_results".to_string(),
        },
        dependencies: vec!["understand"],
        ..Default::default()
    })
    .add_node("query_database", NodeConfig {
        node_type: NodeType::SubgraphNode {
            graph_def: database_tool,
            input_mapping: vec![("sql", "db_query")],
            output_key: "db_results".to_string(),
        },
        dependencies: vec!["understand"],
        ..Default::default()
    })
    
    // Step 3: Reason over results
    .add_node("reason", NodeConfig {
        node_type: NodeType::AINode {
            provider: "openai",
            model: "gpt-4".to_string(),
            system_prompt: "Synthesize information from tools and provide answer.".to_string(),
        },
        dependencies: vec!["search_knowledge", "query_database"],
        ..Default::default()
    })
    
    // Step 4: Validate with business rules
    .add_node("validate", NodeConfig {
        node_type: NodeType::RuleNode {
            rules_file: "validation_rules.grl".to_string(),
        },
        dependencies: vec!["reason"],
        ..Default::default()
    })
    
    // Step 5: Retry on validation failure
    .add_retry("reason", RetryConfig {
        max_attempts: 3,
        backoff_ms: 1000,
        exponential: true,
    });
```

### Architecture Diagram
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM (Claude)      â”‚
â”‚ Understand Intent â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                       â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ Search Tool     â”‚  â”‚ Database Tool   â”‚  â”‚ Calculator  â”‚
â”‚ (Subgraph)      â”‚  â”‚ (Subgraph)      â”‚  â”‚ (Subgraph)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ LLM (GPT-4)        â”‚
                     â”‚ Reason & Synthesizeâ”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Validate (GRL)     â”‚
                     â”‚ Business Rules     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Valid?          â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                     â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
              â”‚  Success  â”‚        â”‚  Retry    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Benefits
- âœ… Multi-step AI reasoning
- âœ… Tool calling with validation
- âœ… Automatic retry logic
- âœ… Business rule compliance

---

## Pattern 3: Saga Pattern for Distributed Transactions

### Problem
Coordinate a transaction across multiple microservices. If any step fails, roll back previous steps with compensation logic.

### Solution
```rust
let order_saga = Graph::new()
    // Step 1: Reserve inventory
    .add_node("reserve_inventory", NodeConfig {
        node_type: NodeType::GrpcNode {
            endpoint: "inventory-service:50051".to_string(),
            method: "ReserveItems".to_string(),
        },
        ..Default::default()
    })
    .add_compensation("reserve_inventory", NodeConfig {
        node_type: NodeType::GrpcNode {
            endpoint: "inventory-service:50051".to_string(),
            method: "ReleaseItems".to_string(),
        },
        ..Default::default()
    })
    
    // Step 2: Charge payment
    .add_node("charge_payment", NodeConfig {
        node_type: NodeType::GrpcNode {
            endpoint: "payment-service:50052".to_string(),
            method: "ChargeCard".to_string(),
        },
        dependencies: vec!["reserve_inventory"],
        ..Default::default()
    })
    .add_compensation("charge_payment", NodeConfig {
        node_type: NodeType::GrpcNode {
            endpoint: "payment-service:50052".to_string(),
            method: "RefundPayment".to_string(),
        },
        ..Default::default()
    })
    
    // Step 3: Create shipment
    .add_node("create_shipment", NodeConfig {
        node_type: NodeType::GrpcNode {
            endpoint: "shipping-service:50053".to_string(),
            method: "CreateShipment".to_string(),
        },
        dependencies: vec!["charge_payment"],
        ..Default::default()
    })
    .add_compensation("create_shipment", NodeConfig {
        node_type: NodeType::GrpcNode {
            endpoint: "shipping-service:50053".to_string(),
            method: "CancelShipment".to_string(),
        },
        ..Default::default()
    })
    
    // Error handling with saga rollback
    .add_saga_error_handler(|error, completed_steps| {
        // Automatically call compensation for completed steps
        for step in completed_steps.iter().rev() {
            step.compensate()?;
        }
        Ok(())
    });
```

### Architecture Diagram
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Order       â”‚
â”‚ Request     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reserve Inventory â”‚ â—€â”€â”€ Compensation: Release Inventory
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Success
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Charge Payment    â”‚ â—€â”€â”€ Compensation: Refund Payment
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Success
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Create Shipment   â”‚ â—€â”€â”€ Compensation: Cancel Shipment
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Success
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Complete Order    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

If any step fails:
       â”‚ Failure
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute           â”‚
â”‚ Compensations     â”‚â—€â”€â”€ Roll back in reverse order
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Benefits
- âœ… Distributed transaction coordination
- âœ… Automatic compensation on failure
- âœ… Fault-tolerant microservices
- âœ… ACID-like guarantees across services

---

## Pattern 4: RAG (Retrieval-Augmented Generation)

### Problem
Build an AI system that:
1. Searches a vector database for relevant documents
2. Generates embeddings for queries
3. Ranks and filters results
4. Uses LLM to generate answers based on retrieved context

### Solution
```rust
let rag_pipeline = Graph::new()
    // Step 1: Generate query embedding
    .add_node("embed_query", NodeConfig {
        node_type: NodeType::AINode {
            provider: "openai",
            model: "text-embedding-ada-002".to_string(),
            ..Default::default()
        },
        ..Default::default()
    })
    
    // Step 2: Vector search
    .add_node("vector_search", NodeConfig {
        node_type: NodeType::DBNode {
            database: "pinecone",
            query: r#"{"top_k": 5, "include_metadata": true}"#.to_string(),
        },
        dependencies: vec!["embed_query"],
        ..Default::default()
    })
    
    // Step 3: Rerank results with business rules
    .add_node("rerank", NodeConfig {
        node_type: NodeType::RuleNode {
            rules_file: "reranking_rules.grl".to_string(),
        },
        dependencies: vec!["vector_search"],
        ..Default::default()
    })
    
    // Step 4: Generate answer with context
    .add_node("generate", NodeConfig {
        node_type: NodeType::AINode {
            provider: "openai",
            model: "gpt-4".to_string(),
            system_prompt: "Use the provided context to answer the question.".to_string(),
        },
        dependencies: vec!["rerank"],
        ..Default::default()
    })
    
    // Step 5: Validate answer
    .add_node("validate_answer", NodeConfig {
        node_type: NodeType::RuleNode {
            rules_file: "answer_validation.grl".to_string(),
        },
        dependencies: vec!["generate"],
        ..Default::default()
    });
```

### Benefits
- âœ… Accurate, grounded AI responses
- âœ… Custom reranking logic
- âœ… Answer validation
- âœ… Modular RAG pipeline

---

## Pattern 5: Event-Driven Reasoning

### Problem
React to events from Kafka/RabbitMQ, apply business rules in real-time, and trigger actions.

### Solution
```rust
let event_processor = Graph::new()
    // Step 1: Consume event
    .add_trigger("kafka_consumer", TriggerConfig {
        source: "kafka://events-topic".to_string(),
        ..Default::default()
    })
    
    // Step 2: Enrich with context
    .add_node("enrich", NodeConfig {
        node_type: NodeType::DBNode {
            database: "postgres",
            query: "SELECT * FROM context WHERE event_id = $1".to_string(),
        },
        ..Default::default()
    })
    
    // Step 3: Apply rules
    .add_node("evaluate_rules", NodeConfig {
        node_type: NodeType::RuleNode {
            rules_file: "event_rules.grl".to_string(),
        },
        dependencies: vec!["enrich"],
        ..Default::default()
    })
    
    // Step 4: Route based on decision
    .add_node("route", NodeConfig {
        node_type: NodeType::ConditionalNode {
            condition: "action_required == true".to_string(),
            true_branch: "trigger_action".to_string(),
            false_branch: "log_event".to_string(),
        },
        dependencies: vec!["evaluate_rules"],
        ..Default::default()
    })
    
    // Circuit breaker for external actions
    .add_circuit_breaker("trigger_action", CircuitBreakerConfig {
        failure_threshold: 5,
        timeout_ms: 60000,
    });
```

### Benefits
- âœ… Real-time event processing
- âœ… Business rule evaluation
- âœ… Fault tolerance with circuit breaker
- âœ… Conditional routing

---

## Pattern 6: Multi-Agent Coordination

### Problem
Coordinate multiple AI agents that:
1. Have specialized roles
2. Share context
3. Make decisions collaboratively
4. Validate each other's outputs

### Solution
```rust
let multi_agent_system = Graph::new()
    // Agent 1: Data Analyst
    .add_node("analyst_agent", NodeConfig {
        node_type: NodeType::AINode {
            provider: "openai",
            model: "gpt-4".to_string(),
            system_prompt: "You are a data analyst. Analyze the data and provide insights.".to_string(),
        },
        ..Default::default()
    })
    
    // Agent 2: Business Strategist
    .add_node("strategist_agent", NodeConfig {
        node_type: NodeType::AINode {
            provider: "claude",
            model: "claude-3-5-sonnet-20241022".to_string(),
            system_prompt: "You are a business strategist. Recommend actions based on analysis.".to_string(),
        },
        dependencies: vec!["analyst_agent"],
        ..Default::default()
    })
    
    // Agent 3: Risk Assessor
    .add_node("risk_agent", NodeConfig {
        node_type: NodeType::AINode {
            provider: "openai",
            model: "gpt-4".to_string(),
            system_prompt: "You are a risk assessor. Evaluate risks of proposed actions.".to_string(),
        },
        dependencies: vec!["strategist_agent"],
        ..Default::default()
    })
    
    // Coordination with business rules
    .add_node("coordination", NodeConfig {
        node_type: NodeType::RuleNode {
            rules_file: "agent_coordination.grl".to_string(),
        },
        dependencies: vec!["analyst_agent", "strategist_agent", "risk_agent"],
        ..Default::default()
    })
    
    // Final decision
    .add_node("final_decision", NodeConfig {
        node_type: NodeType::ConditionalNode {
            condition: "consensus_reached == true && risk_acceptable == true".to_string(),
            true_branch: "execute_action".to_string(),
            false_branch: "escalate_to_human".to_string(),
        },
        dependencies: vec!["coordination"],
        ..Default::default()
    });
```

### Benefits
- âœ… Specialized AI agents
- âœ… Collaborative decision making
- âœ… Risk assessment
- âœ… Human escalation path

---

## ğŸ“š Related Documents

- [Use Cases](USE_CASES.md) - Real-world applications
- [GRL Guide](GRL.md) - Business rule syntax
- [Integrations](INTEGRATIONS.md) - Database & AI integrations
- [Extending Guide](EXTENDING.md) - Custom nodes

---

<div align="center">

**Build distributed reasoning systems with proven patterns**

[Main README](../README.md) â€¢ [Documentation](README.md) â€¢ [Examples](../examples/)

</div>
